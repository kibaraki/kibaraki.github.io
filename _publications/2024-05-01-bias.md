---
title: "Analyzing Occupational Distribution Representation in Japanese Language Models"
collection: publications
category: conferences
permalink: /publication/2024-05-01-bias
excerpt: ''
date: 2024-05-01
venue: 'The Joint International Conference on Computational Linguistics, Language Resources and Evaluation'
paperurl: 'http://kibaraki.github.io/files/2024.lrec-main.86.pdf'
citation: '<b>Katsumi Ibaraki</b>, Winston Wu, Lu Wang, and Rada Mihalcea. 2024. Analyzing Occupational Distribution Representation in Japanese Language Models. In <i>Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)</i>, pages 959â€“973, Torino, Italy. ELRA and ICCL.'
---

[[Paper]](https://aclanthology.org/2024.lrec-main.86/) 

```
@inproceedings{ibaraki-etal-2024-analyzing,
    title = "Analyzing Occupational Distribution Representation in {J}apanese Language Models",
    author = "Ibaraki, Katsumi  and
      Wu, Winston  and
      Wang, Lu  and
      Mihalcea, Rada",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.86/",
    pages = "959--973",
    abstract = "Recent advances in large language models (LLMs) have enabled users to generate fluent and seemingly convincing text. However, these models have uneven performance in different languages, which is also associated with undesirable societal biases toward marginalized populations. Specifically, there is relatively little work on Japanese models, despite it being the thirteenth most widely spoken language. In this work, we first develop three Japanese language prompts to probe LLMs' understanding of Japanese names and their association between gender and occupations. We then evaluate a variety of English, multilingual, and Japanese models, correlating the models' outputs with occupation statistics from the Japanese Census Bureau from the last 100 years. Our findings indicate that models can associate Japanese names with the correct gendered occupations when using constrained decoding. However, with sampling or greedy decoding, Japanese language models have a preference for a small set of stereotypically gendered occupations, and multilingual models, though trained on Japanese, are not always able to understand Japanese prompts."
}
```
